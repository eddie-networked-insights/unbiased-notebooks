{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, Embedding, SpatialDropout1D, Dropout, add, concatenate\n",
    "from keras.layers import CuDNNLSTM, Bidirectional, GlobalMaxPooling1D, GlobalAveragePooling1D\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing import text, sequence\n",
    "from keras.callbacks import LearningRateScheduler\n",
    "\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n"
     ]
    }
   ],
   "source": [
    "model = load_model(\"second-model-2019-06-26 14:19:54.312555.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "with open('tokenizer.pkl', 'rb') as f:  # Python 3: open(..., 'rb')\n",
    "    tokenizer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variable                 Type              Data/Info\n",
      "----------------------------------------------------\n",
      "Adam                     type              <class 'keras.optimizers.Adam'>\n",
      "Bidirectional            type              <class 'keras.layers.wrappers.Bidirectional'>\n",
      "CuDNNLSTM                type              <class 'keras.layers.cudnn_recurrent.CuDNNLSTM'>\n",
      "Dense                    type              <class 'keras.layers.core.Dense'>\n",
      "Dropout                  type              <class 'keras.layers.core.Dropout'>\n",
      "Embedding                type              <class 'keras.layers.embeddings.Embedding'>\n",
      "GlobalAveragePooling1D   type              <class 'keras.layers.pool<...>.GlobalAveragePooling1D'>\n",
      "GlobalMaxPooling1D       type              <class 'keras.layers.pooling.GlobalMaxPooling1D'>\n",
      "Input                    function          <function Input at 0x7fa309bc6158>\n",
      "LearningRateScheduler    type              <class 'keras.callbacks.LearningRateScheduler'>\n",
      "Model                    type              <class 'keras.engine.training.Model'>\n",
      "SpatialDropout1D         type              <class 'keras.layers.core.SpatialDropout1D'>\n",
      "add                      function          <function add at 0x7fa309b9c048>\n",
      "concatenate              function          <function concatenate at 0x7fa309b237b8>\n",
      "f                        BufferedReader    <_io.BufferedReader name='tokenizer.pkl'>\n",
      "load_model               function          <function load_model at 0x7fa309b6d7b8>\n",
      "model                    Model             <keras.engine.training.Mo<...>object at 0x7fa309ac2ac8>\n",
      "np                       module            <module 'numpy' from '/us<...>kages/numpy/__init__.py'>\n",
      "pd                       module            <module 'pandas' from '/u<...>ages/pandas/__init__.py'>\n",
      "pickle                   module            <module 'pickle' from '/u<...>lib/python3.5/pickle.py'>\n",
      "sequence                 module            <module 'keras.preprocess<...>eprocessing/sequence.py'>\n",
      "text                     module            <module 'keras.preprocess<...>s/preprocessing/text.py'>\n",
      "tokenizer                Tokenizer         <keras_preprocessing.text<...>object at 0x7fa2f30ac668>\n",
      "tqdm                     type              <class 'tqdm._tqdm.tqdm'>\n"
     ]
    }
   ],
   "source": [
    "%whos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_MODELS = 2\n",
    "# the maximum number of different words to keep in the original texts\n",
    "# 40_000 is a normal number\n",
    "# 100_000 seems good too\n",
    "MAX_FEATURES = 100000 \n",
    "\n",
    "#this is the number of training sample to put in theo model each step\n",
    "BATCH_SIZE = 512\n",
    "\n",
    "#units parameters in Keras.layers.LSTM/cuDNNLSTM\n",
    "#it it the dimension of the output vector of each LSTM cell.\n",
    "LSTM_UNITS = 128\n",
    "DENSE_HIDDEN_UNITS = 4 * LSTM_UNITS\n",
    "\n",
    "EPOCHS = 4\n",
    "\n",
    "#we will convert each word in a comment_text to a number.\n",
    "#So a comment_text is a list of number. How many numbers in this list?\n",
    "#we want the length of this list is a constant -> MAX_LEN\n",
    "MAX_LEN = 220"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "strHist = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one liner to get prediction for any string using the last model (NOTE: removes words that aren't in tokenizer.word_index)\n",
    "inputStr = \"Trump is a piece of shit\"\n",
    "strHist[inputStr] = model.predict(sequence.pad_sequences(tokenizer.texts_to_sequences(np.array([inputStr], dtype=object)), maxlen=MAX_LEN), batch_size=2048)[0].flatten()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Trump is a piece of shit': 0.9999629}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "strHist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
